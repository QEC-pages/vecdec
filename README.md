# vecdec - vectorized decoder and LER estimator

## Overview 

The program can do several kinds of calculations depending on the value of the
`mode` command-line argument:

- `mode=0` Run a vectorized Random Information Set decoder using the
  error data generated by the program itself or externally generated
  (e.g., using `Stim`).  See the [Vectorized decoder](#vectorized-decoder) section.
- `mode=1` Run belief propagation decoder.  See the [BP decoder](#bp-decoder) section
- `mode=2` Estimate logical error rate by enumerating most likely errors.  See
  the [LER estimator](#ler-estimator) section.
- `mode=3` Parse the DEM file and save the corresponding matrices to
  files.  See the [Export the matrices](#export-the-matrices) section.
  
In any mode, the program requires the parity check matrices and error
probabilities, e.g., as given in a Detector Error Model (DEM) file,
see the [Error model](#error-model) section.

Some examples of using `vecdec` in various modes are given in the
[Common tasks](#common-tasks) section.

For additional details, see the [section](#-all-command-line-arguments) on
command-line arguments, the source code in `vecdec/src` directory, and example
scripts in `vecdec/examples` and `vecdec/input` directories.


## Installation 

The program uses `m4ri` library for binary linear algebra.
To install this library on a Ubuntu system, run
    `sudo apt-get install libm4ri-dev`
    
To run scripts in `vecdec/examples` directory, you will need to install
command-line versions of [Stim](https://github.com/quantumlib/Stim) and
[PyMatching](https://github.com/oscarhiggott/PyMatching).
    
For compilation *help*, change to the (vecdec/src/) directory and just run w/o
arguments  
    `make`
Since the program  is experimental, I recommend compiling with  
    `make vecdec EXTRA=""` 
This will enable additional integrity
checks, and a lot of optional debugging information.

## Error model

A detector error model (DEM) is a collection of independent `events`, each of
which is characterized by a probability `p`, a list of affected syndrome bits,
and a list of affected codewords.  Can be created by `stim`, see shell scripts
in the (vecdec/examples/) directory.  Notice that `stim` cycles are not
supported in the DEM file.  Only the lines starting with `error` are used; the
`detector` and `shift_detectors` are silently ignored, as well as any comments.
Any other entry will trigger an error.

```
# An example DEM file created by `stim`
error(0.125) D0
error(0.125) D0 D1
error(0.125) D0 D2
error(0.125) D1 D3
error(0.125) D1 L0
error(0.125) D2 D4
error(0.125) D3 D5
error(0.125) D4 D6
error(0.125) D5 D7
detector(1, 0) D0
detector(3, 0) D1
shift_detectors(0, 1) 0
detector(1, 0) D2
detector(3, 0) D3
shift_detectors(0, 1) 0
detector(1, 0) D4
detector(3, 0) D5
detector(1, 1) D6
detector(3, 1) D7
```

Alternatively, the error model can be specified in terms of CSS
matrices `H=Hx` and `L=Lx` (use command-line parameters `finH=` and
`finL=` to provide the file names).  For a quantum code, instead of
`L`, the dual CSS generator matrix `G=Hz` can be given.

All matrices with entries in `GF(2)` should have the same number of
columns, `n`, and obey the following orthogonality conditions:
$$H_XH_Z^T=0,\quad H_XL_Z^T=0,\quad L_XH_Z^T=0,\quad L_XL_Z^T=I,$$
where $I$ is an identity matrix.  Notice that the latter identity is
not required; it is sufficient that `Lx` and `Lz` matrices have the
same full row rank `=k`, the dimension of the code, each row of `Lx`
has a non-zero scalar product with a row of `Lz`, and vice versa.

The program can read matrices from files in sparse (`coordinate`)
MaTrix market exchange (`MTX`) format and David MacKay's `alist`
format (the format is recognized automatically).

## Common tasks 

### Simulate the performance of a classical code 

- **Use the internal random information set (RIS) decoder.** Use a
  classical code specified by a parity check matrix in Matrix Market
  coordinate (`MTX`) or David MacKay's `alist` format; errors in this
  mode can only be generated internally.  The following command line
  uses the LDPC code `[96,48,6]` from David MacKay collection
  (https://www.inference.org.uk/mackay/codes/data.html) in the file
  `./examples/96.3.963.alist`:
  
```
vecdec=./src/vecdec
$vecdec debug=1 mode=0 finH= ./examples/96.3.963.alist \
  ntot=10240 nvec=1024 steps=5000 lerr=1 useP=0.05 nfail=100
```

This example generates up to `ntot=10240` random error vectors in
bunches of size `nvec=1024` each (for best performance, make sure that
`nvec` be divisible by `64` and is not smaller than `1024`).  Uniform
error probability `P=0.05` is chosen for each variable node.  The run
will stop after encountering `nfail=100` decoding errors.  Linear
algebra part of Random Information Set decoding is also done in
bunches; total of `steps=5000` random information sets are taken.  For
each of these, vectors with information sets of weight up to `lerr=1`
are examined.

In a particular run the block error rate (BER) `0.0249023` (`102` out
of `4096`) was achieved.  Increasing the number of RIS decoding steps
by a factor of 10 **increased** BER to `0.029541` (`121` out of
`4096`). [**FIXME:** *This looks like a bug - likely in the OSD module
-- nothing like this happens with `lerr=-1`!*]

- **Use Belief Propagation (BP) disorder with optional OSD.** Same
  code, using up to `steps=50` BP iterations with parallel update
  schedule, using both average and instantaneous LLR (whichever
  converges first), followed by OSD1 (`lerr=1`) using up to
  `maxosd=50` columns:
  
```
vecdec=./src/vecdec
$vecdec debug=1 mode=1 maxosd=50 steps=50 lerr=2 \
    finH= ./examples/96.3.963.alist ntot=102400 nvec=102400 useP=0.05 seed=5
```
Here equal `ntot` and `nvec` are used to ensure that the 
random error sample remains the same (for reproducibility with the `seed` set).
This particular example using OSD2 gives BER of `0.0325` (`3328`
failed out of `102400`); using a lower OSD1 gives a BER of
`0.0397754`.

To use BP with serial-`C` or serial-`V` update schedules, use
`mode=1.4` (bit `2` set in the `submode`) and `mode=1.12` (both bit
`2` and bit `3` are set) respectively.  Bits `0` and bits `1` are used
to specify just instantaneous or just average LLR values, e.g.,
`mode=1.1` for parallel update schedule with instantaneous LLR,
`mode=1.14` for serial-`V` update schedule with average LLR.  For this
particular code and set of errors, `mode=1.14` gives the best
performance, with BER of `0.0390918` (`4003` out of `102400`).

- **Find the distance of a classical code and estimate the LER.** The
  program in `mode=2` uses RIS algorithm to enumerate small-weight
  codewords and estimate the LER based on the codewords available.
  The list of codewords can be exported to and imported from a file
  and therefore reused with a different error model.
  
  The following example uses `100,000` RIS steps to enumerate
  codewords of up to `dW=10` above the minimum weight found (for this
  particular code the code distance `minW=6`) and write them to a file
  `tmp.nz`.
```
vecdec=./src/vecdec
$vecdec mode=2 steps=100000 finH= ./examples/96.3.963.alist useP=0.05 outC=tmp.nz dW=10
```
In a particular run, `195769` codewords has been generated; more
  codewords can be found by repeating the runs using the command line
```
$vecdec mode=2 steps=100000 finH= ./examples/96.3.963.alist useP=0.05 \
  finC=tmp.nz outC=tmp.nz dW=10
```
In a particular set of three subsequent runs, `210822`, `212203`, and
`212314` codewords were written to the file.  The computed codewords
can be used to estimate the BER, e.g, by running a `bash` script 
```
for ((w=6; w<=16; w++)) ; do 
  echo $w `$vecdec debug=0 mode=2 steps=0 \
  finH= ./examples/96.3.963.alist useP=0.05 finC=tmp.nz maxW=$w`  
done
```
which gives the output
```
6 0.020577 0.006859 6 3
7 0.020577 0.006859 6 3
8 0.051854 0.006859 6 27
9 0.051854 0.006859 6 27
10 0.100138 0.006859 6 222
11 0.100138 0.006859 6 222
12 0.190795 0.006859 6 2149
13 0.190795 0.006859 6 2149
14 0.361757 0.006859 6 21275
15 0.361757 0.006859 6 21275
16 0.68621 0.006859 6 212314
```
The second column is a greedy estimate for the LER (sum over
contributions for each codeword), the third is the single maximum term
in the sum, the fourth is the minimum weight of a codeword, and the last
column is the total number of codewords used in the estimate.
Clearly, the error probability `0.05` is too high for good convergence.  With
a smaller error probability `useP=0.01`, a much better convergence is
achieved:
```
6 0.000186297 6.20991e-05 6 3
7 0.000186297 6.20991e-05 6 3
8 0.000245316 6.20991e-05 6 27
9 0.000245316 6.20991e-05 6 27
10 0.000264306 6.20991e-05 6 222
11 0.000264306 6.20991e-05 6 222
12 0.000271737 6.20991e-05 6 2149
13 0.000271737 6.20991e-05 6 2149
14 0.000274658 6.20991e-05 6 21275
15 0.000274658 6.20991e-05 6 21275
16 0.000275813 6.20991e-05 6 212314
```
A much longer run over a million error samples in `mode=0` and
`steps=1000` (definitely not sufficient for optimal minimum-weight
decoding of this code) 
```
$vecdec debug=1 mode=0 steps=1000 lerr=1 finH= ./examples/96.3.963.alist useP=0.01 nvec=100000 ntot=1000000
```
gives the BER of `3.1e-5` (`31` out of `1000000`), which is an order of
magnitude below the greedy estimate and even factor of two below the estimate based
on a single codeword.  This is the result of a very rough prefactor
value used in the estimate.  (**FIXME:** Come up with a more accurate
prefactor calculation.)

### Simulate the performance of a quantum CSS code 

- Use RIS decoder (`mode=0`) with a quantum CSS code specified by parity check matrices `Hx`
  and `Hz`; generate errors internally.  In this particular example,
  the generalized bicycle (GB) code `[[10,2,3]]` with row weight `6` specified by the MTX files
  `./input/GB_10_w6_X.mtx` and `./input/GB_10_w6_Z.mtx` is used:
```bash
vecdec=./src/vecdec 
$vecdec debug=1 mode=0 finH= ./input/GB_10_w6_X.mtx \
                       finG= ./input/GB_10_w6_Z.mtx \
					useP=0.005 lerr=1 nvec=10240 ntot=102400 steps=5000 
```
which gives the BER of `0.000908203` (`93` errors out of `102400`).

- Use BP decoder with serial-`V` schedule based on average LLR
```
 $vecdec debug=1 mode=1.14 finH= ./input/GB_10_w6_X.mtx \
                           finG= ./input/GB_10_w6_Z.mtx \
					   useP=0.005 lerr=2 nvec=10240 ntot=102400 steps=100
```
gives the BER of `0.00140625` (`144` out of `102400`). 

- Estimate the BER by generating the list of codewords 
```
$vecdec debug=1 mode=2 finH= ./input/GB_10_w6_X.mtx \
                       finG= ./input/GB_10_w6_Z.mtx \
				    useP=0.005 steps=1000000 finC=tmp.nz outC=tmp.nz dW=7
```
and a subsequent cycle over the maximum weight:
```
for ((w=3; w<=10; w++)) ; do 
  echo $w `$vecdec debug=0 mode=2 finH=./input/GB_10_w6_X.mtx \
      finG=./input/GB_10_w6_Z.mtx useP=0.005 steps=0 finC=tmp.nz  maxW=$w` 
done
```
which gives 
```
3 0.0280724 0.00280724 3 10
4 0.0320325 0.00280724 3 20
5 0.0327029 0.00280724 3 32
6 0.0327029 0.00280724 3 32
7 0.0327029 0.00280724 3 32
8 0.0327029 0.00280724 3 32
9 0.0327029 0.00280724 3 32
10 0.0327029 0.00280724 3 32
```
Again, the estimated contribution from a single codeword is about twice the LER computed.

### Simulate quantum Clifford circuit (given a detector error model)

In this particular example, detector error model (DEM) file is
generated by `Stim` for a specific quantum circuit.  Namely, a $d=5$
surface code with $5$ rounds of measurements and a standard circuit
error model with the same probability `p=0.005` of four common error types: 
```bash
vecdec=./src/vecdec
stim=../Stim/out/stim # location of `stim` command-line binary
d=5                      # code distance (and number of rounds)
p=0.005                  # error probability to use 
fnam=sd5                 # base file name to use for `stim` files 
# use `Stim` to create the actual circuit 
$stim gen --code surface_code --task rotated_memory_x \
          --distance $d --rounds $d \
          --after_clifford_depolarization $p \
          --after_reset_flip_probability $p \
          --before_round_data_depolarization $p \
          --before_measure_flip_probability $p \
          > $fnam.stim
# use `Stim` to create the DEM file 
$stim analyze_errors --in $fnam.stim > $fnam.dem
# use `vecdec` to generate errors internally and do the actual decoding
$vecdec debug=1 mode=0 fdem=$fnam.dem steps=500 lerr=1 \
          ntot=10240 nvec=1024 nfail=100 
```
This gives BER of `0.0581055` (`119` out of  `2048`).  Note that the
DEM file, in effect, specifies matrices `H=Hx`, `L=Lx`, and the error
probabilities in different variable nodes.  In this particular case,
the code has parameters `[[1679,1,5]]`.  The number of RIS decoding
`steps=500` is too small for this long a code.

The same result can be also achieved by specifying these parameters in
different files: `finH=$H finL=$L finP=$P`, where `$H`, `$L` and `$P`,
respectively, are names of the files with the two matrices and the
error probability vector.  To generate these files from a DEM file,
use `vecdec` with `mode=3`: 
```
$vecdec mode=3.28 fdem=sd5.dem fout=tmp 
```
This creates the files `tmpH.mmx`, `tmpL.mmx`, and `tmpP.mmx` with
matrices `H` and `L` and the probability vector `P` extracted from the
DEM file.  The submode bitmap `28=4+8+16` specifies the matrices to 
generate, and `fout=tmp` gives the beginning of the file names to
create.  [**FIXME:** `mode=3.1` and `mode=3.2` causes the program to fail]

The command line to use these files (in this case for BP decoding): 
```
$vecdec mode=1.14 finH=tmpH.mmx finL=tmpL.mmx finP=tmpP.mmx steps=50 lerr=2 \
          ntot=10240 nvec=1024 nfail=100
```
It gives BER of `0.0103306` (`100` out of `9680`), substantially
better than the RIS decoding.  Finally, to estimate the decoding
performance, `mode=2` can be used:
```
vecdec=./src/vecdec 
$vecdec mode=2 fdem=sd5.dem steps=100000 dW=7 outC=tmp.nz 
for ((w=5; w<=12; w++)) ; do 
  echo $w `$vecdec debug=0 mode=2 fdem=sd5.dem steps=0 maxW=$w finC=tmp.nz`
done
```
This the output (truncated at the top)
```
# sumP(fail) maxP(fail) min_weight num_found
0.184833 0.000686607 5 5458643
# wrote 5458643 computed codewords to file tmp.nz
5 0.0757023 0.000686607 5 13785
6 0.164425 0.000686607 5 175286
7 0.182536 0.000686607 5 531246
8 0.18459 0.000686607 5 1085981
9 0.184808 0.000686607 5 1853386
10 0.184829 0.000686607 5 2838376
11 0.184832 0.000686607 5 4042564
12 0.184833 0.000686607 5 5458643
```
While the expansion converges, clearly, the greedy estimate is nearly
two orders of magnitude bigger than the actual error rate, while the
single largest contribution to the sum is several orders of magnitude
too small.  Evidently, the reason is the large number (`13785`) of
minimum-weight vectors associated with this particular DEM.

## Use matrix transformations to simplify the error model

The transformations [@Pryadko-2020] reduce the degeneracy of a quantum
code while preserving the maximum-likelihood (ML) decoding
performance.  These correspond to *inverse decoration* or
*star-triangle* (more generally, *star-polygon*) transformations in
the equivalent Ising models.  Namely, *inverse decoration* combines
two identical columns in the matrices `H=Hx` and `L=Lx` (degeneracy
vector of weight `2` removal), while *star-triangle* removes a
degeneracy vector of weight `3`.  More general *star-polygon*
transformation can remove degeneracy vectors of higher weight
(currently not implemented).

Start with the `H=Hx` matrix and the probability vector `P` in files
`tmpH.mmx` and `tmpL.mmx` created earlier and generate a list of (classical)
codewords of weight `3` orthogonal to the rows of `H`
```
$vecdec mode=2 finH=tmpH.mmx steps=10000 maxW=3 finP= tmpP.mmx outC=tmp.nz
```
This creates a file with `5739` vectors.

- Use `vecdec` with detector and observable events generated by
  `Stim` (same shell variables as in the example above):

```bash
$stim  sample_dem --shots 10240 --in $fnam.dem \
        --out $fnam.det --out_format 01 \
        --obs_out $fnam.obs --obs_out_format 01
$vecdec debug=1 mode=0 fdem=$fnam.dem fdet=$fnam.det fobs=$fnam.obs steps=50 lerr=1 \
           nvec=1024 nfail=100 
```

**FIXME:** this gives an error when verifying the codewords read.

### Calculate the distance of a code or a circuit
 
Just use `mode=2`.  For larger circuits this may require a large
number of steps.  For example, for the DEM file
`./examples/surf_d7.dem` (it was originally generated with the help of
`Stim`) we run
```
$vecdec debug=0 mode=2 steps=10000 fdem= ./examples/surf_d7.dem
```
to get the output 
```
8.53809e-06 1.26044e-06 7 19
```
where the third number (`7`) is the minimum weight of a codeword
found, and `19` is the number of codewords found.  Re-run with the
additional parameter `maxW=7` to give the number of codewords of this
weight found:
```
./src/vecdec debug=0 mode=2 steps=1000 fout=tmp2 fdem= ./examples/surf_d7.dem maxW=7
9.12457e-06 1.26044e-06 7 99
```


### Save the files 



## Vectorized decoder

This section describes operation with the command-line switch `mode=0`
(the default).

### How it works 

Given a binary vector `s` with detector events, the goal is to construct the
most likely binary vector `e` such that `H*e=s`.  The decoding is verified by
computing the vector of observable bits `L*e` and comparing it with the
corresponding result computed from the actual error.

The random errors and the corresponding detector/observable vectors can be
generated on the fly (for a given error model), or read from files in 01
format.

The program processes up to `nvec` syndrome vectors at a time.  The syndrome
columns are written as columns of a binary matrix `S`.  The original check
matrix `H` (extracted from the error model) is combined with `S`, to form
block-matrix `[H,S]`.  At each step, a column ordering `P` is randomly generated
(using values of event probabilities to help), the Gauss elimination is
performed on the rows of the combined matrix, creating the list of pivot columns
`[i0, i1, ...]`, with one entry per row.  Given the transformed syndrome column
`[s0, s1, ...]`, the output vector has values given by the list of pairs
`[(i0,s0), (i1,s1), ...]`.  The energy is calculated as the sum of LLRs for
non-zero bits in `e` and recorded, along with the sparse form of `e` if the
energy is small enough.

The program stops after a sufficient number of attempts is made, and compares
the values `L*e` for each found error `e` with the similar ones generated from
the original errors; any mismatch is a logical error.

### How to run it

The `suggested` number of syndrome vectors to generate and process is given by
`ntot`.  In reality, the number of rounds is calculated as $\lceil$ `ntot/nvec`
$\rceil$, where `nvec` is another command line argument (currently, the default
`nvec=16`, although one should probably use at least `1023` for efficiency).  In
each round, `nvec` different syndrome vectors will be generated and processed.
Ideally, `nvec` should be a factor `64`, since 64-bit integers are used to store
binary vectors internally.

The parameter `nfail`, when non-zero, will cause execution to stop after
accumulating a given number of logical errors.

The parameter `lerr`, when non-zero, specifies the maximum number of
non-zero error bits outside of the index set to try before generating
a new permutation.  This is similar to OSD level.  For large codes,
recommended values are `lerr=0` and `lerr=1`; larger values make the
program prohibitively slow (run-time generally scales as code length
to the power of `lerr`).

Another important command-line parameter is `steps`.  It should be set
to a sufficiently large number (experiment!) for decoding to be
accurate, especially close to the threshold.  The related parameter
`swait` (if non-zero) specifies the number of steps w/o any updates to
any error vector to wait before terminating the cycle.

Use `debug=0` to suppress any output except for simulation results.
Use `debug=1023` to output all possible debugging information (not all
bits are used at this time).  The default value `debug=1` causes the
program to print information about basic steps of the calculation.

Use `fdem=filename` (with or without quotes) or `fdem= filename` (with
a space) to specify the input file with the detector error model.

You may also want to set the names of the input files with externally
generated errors, e.g., using the command-line arguments 
`fdet=dets.01 fobs=obs_flips.01`

## BP decoder 

Activate it with the command-line parameters `mode=1`.  Several
variants of the BP decoder are implemented; these are controlled by
the `submode` bitmap, and also by parameters `bpalpha`, `bpretry`,
`lerr`, and `maxosd`.

### submode bitmap values 

The `submode` bitmap is specified after a decimal point in the mode
parameter, e.g., `mode=1.14` has `submode=14` ($=2+4+8=2^1+2^2+2^3$), which corresponds
to set bits `1`, `2`, and `3`.  As detailed below, this gives `serial-V`
BP schedule based on `average LLR`.

- bit `0` in the bitmap controls the use of regular (instantaneous)
  LLR to check the convergence.  Namely, when bit `0` is set,
  instantaneous LLR will be used.
  
- bit `1` controls the use of average LLR to check the convergence.

  When both bit `0` and bit `1` are set, both sets of LLR values will
  be computed and used sequentially after every round of BP to check
  the convergence.  For convenience, when `neither` bit `0` nor bit
  `1` is set, both sets of LLR values will be computed and used.
  
- when bit `2` is set, `serial` BP update schedule is used, otherwise
  `parallel` schedule.  Additional options for `serial` schedule are
  set by bits `3` and `4` (these only have effect with serial BP
  schedule, i.e., when bit `2` is set):
  - when bit `3` is set, `serial-V` order is selected, otherwise `serial-C`
  - when bit `4` is set, node randomization is done at every round, as
    opposed to once per run with a given syndrome vector.
	
### additional parameters affecting BP 

- parameter `bpalpha` (allowed range from 0.0 to 1.0; the default
  value is `0.5`) sets the coefficient for calculating average LLR
  values.  Smaller values correspond to shorter memory; setting
  `bpalpha=0` gives the same result at instantaneous LLR.

- parameter `bpretry` (integer, default value `1`, do not retry)
  allows to repeat BP several times using different node permutations.
  The prescribed number of attempts is made until a solution which
  satisfies the syndrome is found.  This is useless with the
  `parallel` schedule (**TODO:** randomization of prior probabilities).
  
- the use of optional ordered-statistics decoding (OSD) after BP
  failed to converge is controlled by the parameters `lerr` (default
  `-1`) and `maxosd` (default `100`).  With OSD, the variable nodes
  are sorted by decreasing error probability (according to BP), and
  Gauss elimination is used to find valid error vectors.  With
  `lerr=0`, the unique solution corresponds to all-zero information
  set (variable nodes corresponding to pivot columns), with `lerr=1`, in addition to all-zero information set,
  information sets with a single non-zero bit are also checked, and
  the minimum-weight vector is selected; with `lerr=2` up to two
  non-zero bits are selected, etc.  When `maxosd` parameter is
  non-zero, the search with *multiple* non-zero information bits is
  restricted to this range of columns (default value `maxosd=100`).

### Quantized LLR and `min-sum` vs. `sum-product` BP updates

When the program is compiled with `USE_QLLR` (the default), parameters
of integer-based Quantized LLR module can be set using `qllr#=int`,
where `#` can be 1, 2, or 3.  By default, the recommended values
`qllr1=12 qllr2=300 qllr3=7` are used.

The power `1<<qllr1` determines how integral LLRs relate to real LLRs
(`to_double=(1<<qllr1)*int_llr`).  Table resolution is
`2^(-(qllr1-qllr3))`.  The parameter `qllr2` is the number of entries
in a table for LLR operations.  With `qllr2=0` (no table), the
`Sum-Product` algorithm used in the program effectively reduces to a
`Min-Sum` algorithm.

## LER and code distance estimator

This section describes operation with the command-line switch `mode=2`.

Given the error model, i.e., the matrices $H$, $L$, and the vector of column
probability values $p_i$, the program tries to enumerate the likely binary
`codewords` $c$ such that $He=0$, $Le\neq0$, 
while the associate log-likelihood probability ratio (LLR) 
$\sum_i c_i \ln(1/p_i-1)$
is not too large. 

To this end, it stores the list of codewords found in a hash, and
outputs four numbers: 
- The sum of estimated contributions to the logical error probability
  from all codewords found, $\displaystyle\sum_c\prod_{i\in
  \mathop{\rm supp}c} 2[ p_i(1-p_i)]^{1/2}$.  If the list of codewords
  is large enough, this gives an upper bound on the fail probability.
- Maximum fail probability from a single codeword (maximum term
  contributing to the sum above).  Up to a prefactor, this gives a
  lower bound on the fail probability.
- Minimum weight of the codeword found.  This gives the code distance
  (`Z`-distance for a CSS code with `H=Hx`, `G=Hz`).  This is
  particularly useful if you want to compare the circuit distance with
  that of the original code.
- Number of codewords contributing to the total.  With `dW=0`, this
  gives the total number of distinct minimum-weight codewords found.

To speed up the distance calculation, you can use the parameter `dmin`
(by default, `dmin=0`).  When non-zero, if a code word of weight `w`
$\le$ `dmin` is found, the distance calculation is terminated
immediately, and the result `-w` with a negative sign is printed.
This is useful if, e.g., we are trying to construct a fault-tolerant
measurement circuit whose circuit distance should coincide with the
distance `d` of the original code.  In this case, if we specify
`dmin=(d-1)`, distance calculation will be terminated immediately so
that a different circuit can be studied.

Additional parameters relevant for this mode: 

- `finC` optional filename to read the list of codewords from
  (default: empty, do not read).  Notice that the energy of the
  codewords is not stored in the file, it will be recomputed.  The
  codewords read are verified after reading; error will result if any
  codeword does not satisfy the orthogonality conditions, `H*c=0`,
  `L*c!=0` (this may happen, e.g., if an incorrect file was specified).
- `outC` optional filename to write the full list of codewords to
  (default: empty, do not write).
- `maxC` maximum number of codewords to read/write/create (default: `0`, no limit).
- `dW` maximum weight of codewords above the minimum weight (default:
  `0`, just keep the minimum weight codewords).  Setting `dW=-1`
  suppresses the upper limit on the weight of codewords stored.
- `dE` maximum energy of codewords above the minimum energy (default:
  `-1`, no limit on the energy of codewords found).

## Export the matrices 

This section describes operation with the command-line switch
`mode=3`.  In this case the program does not try to run anything and
just parses the DEM file and saves the corresponding parity-check
`H=Hx`, observables `L=Lx` matrices and the error-probabilities `P`
vector.  In addition, the program constructs the `G=Hz` and `K=Lz`
matrices.  As a reminder, rows of `G` are orthogonal to rows of `H`
and `L`, while rows of `K` are orthogonal to the rows of `H`, are
linearly independent from rows of `G`, and each has a non-zero product
with a row of `L`.  Also, `rank H + rank G = n-k`, `rank L = rank K =
k`, where `n` is the number of variable nodes (matrix columns) and `k`
is the dimension of the code.  For a classical code, matrix `G` is
trivial (has zero rank), while the `L` matrix can be selected to have
all rows of weight `1`.

The matrices are written in the Matrix Market format to files with names
`${fout}H.mmx`, `${fout}G.mmx`, `${fout}L.mmx`, and `${fout}P.mmx`,
where the header string is defined by the value of the `fout=`
command-line argument.  An exceptional value is `fout=stdout`, in
which case the contents of the files is directed (surprise!) to
`stdout`.

**Note:** For some obscure reasons, the constructed `G` matrix will
 only have weight-3 rows.  This is done by finding triplets of columns
 in matrices `H` and `L` which sum to zero.  This works for a DEM file
 created from a circuit which contains one- or two-qubit depolarizing
 noise.  With insufficient rank in weight-3 rows, the program will
 currently fail.


## All command-line arguments 

You can generate the list of supported command line arguments by running 
`vecdec --help`.

```bash
./vecdec:  vecdec - vectorized decoder and LER estimator
  usage: ./vecdec param=value [[param=value] ... ]
	 Command line arguments are processed in the order given.
	 Supported parameters:
	 --help		: give this help (also '-h' or just 'help')
	 --morehelp	: give more help
	 fdem=[string]	: name of the input file with detector error model
	 finH=[string]	: file with parity check matrix Hx (mm or alist)
	 finG=[string]	: file with dual check matrix Hz (mm or alist)
	 finL=[string]	: file with logical dual check matrix Lx (mm or alist)
	 finK=[string]	: file with logical check matrix Lz (mm or alist)
	 finP=[string]	: input file for probabilities (mm or a column of doubles)
	 finC=[string]	: input file name for codewords in `nzlist` format
	 outC=[string]	: output file name for codewords in `nzlist` format
			 (if same as finC, the file will be updated)
	 maxC=[long long int]	: max number of codewords to read/write/store
	 epsilon=[double]	: small probability cutoff (default: 1e-8)
	 useP=[double]	: fixed probability value (override values in DEM file)
		 for a quantum code specify 'fdem' OR 'finH' and ( 'finL' OR 'finG' );
		 for classical just 'finH' (and optionally the dual matrix 'finL')
	 ferr=[string]	: input file with error vectors (01 format)
	 fdet=[string]	: input file with detector events (01 format)
	 fobs=[string]	: input file with observables (01 matching lines in fdet)
		 specify either 'ferr' OR a pair of 'ferr' and 'fdet' (or none for internal)
	 fout=[string]	: header for output file names ('tmp', see 'mode=3')
		 (space is OK in front of file names to enable shell completion)
	 steps=[integer]	: num of RIS or BP decoding steps (default: 50)
	 lerr =[integer]	: OSD search level (-1, only implemented with `mode=0`, `1`)
	 maxosd=[integer]	: max column for OSD2 and above (100)
	 bpalpha=[float]	: average LLR scaling coefficient for BP (default 0.5)
	 bpretry=[integer]	: retry BP up to this many times per syndrome (1)
	 swait=[integer]	: Gauss steps w/o new errors to stop (0, do not stop)
	 nvec =[integer]	: max vector size for decoding (default: 1024)
			 (list size for distance or energy calculations)
	 ntot =[long long int]	: total syndromes to generate (default: 1)
	 nfail=[long long int]	: total fails to terminate (0, do not terminate)
	 dW=[integer]	: if 'dW>=0', may keep vectors of weight up to 'minW+dW' (0)
	 maxW=[integer]	: if non-zero, skip any vectors above this weight (0)
	 dE=[double]	: if 'dE>=0', may keep vectors of energy up to 'minE+dE'
			 (default value: -1, no upper limit on energy)
	 dmin=[integer]	: terminate distance calculation immediately when
			 a vector of weight 'W<=dmin' is found, return '-w' (default: 0)
	 seed= [long long int]	: RNG seed or automatic if <=0 (default: 0)
	 qllr1=[integer]	: if 'USE_QLLR' is set, parameter 'd1' (12)
	 qllr2=[integer]	: if 'USE_QLLR' is set, parameter 'd2' (300)
	 qllr3=[integer]	: if 'USE_QLLR' is set, parameter 'd3' (7)
		 These are used to speed-up LLR calculations, see 'qllr.h'
		 Use 'qllr2=0' for min-sum.
	 mode=int[.int]	: operation mode[.submode] (default: 0.0)
		* 0: use basic vectorized (random information set) decoder
			 read detector events from file 'fdet' if given, otherwise
			 generate 'ntot' detector events and matching observable flips;
			 decode in chunks of size 'nvec'. 
			 Read observable flips from file 'fobs' if given
		* 1: Belief Propagation decoder.  By default (no submode specified)
			   parallel BP using both regular and average LLRs.
			   Other options are selected by 'submode' bitmap: 
			 .1 (bit 0) use regular LLR
			 .2 (bit 1) use average LLR - these take precendence
			 .4 (bit 2) use serial BP schedule (not parallel)
			 .8 (bit 3) with serial, use V-based order (not C-based)
			 .16 (bit 4) with serial, randomize node order in each round 
			     (by default randomize only once per run)
		* 2: generate most likely fault vectors, estimate Prob(Fail).
			 Use up to 'steps' random information set (RIS) decoding steps
			 unless no new fault vectors have been found for 'swait' steps.
			 Keep vectors of weight up to 'dW' above min weight found.
			       and energy up to 'dE' above min E found.
			 When 'maxC' is non-zero, generate up to 'maxC' unique codewords.
			 If 'outC' is set, write full list of CWs to this file.
			 If 'finC' is set, read initial set of CWs from this file.
		* 3: Read in the DEM file and optionally write the corresponding 
			 G, K, H, and L matrices and the probability vector P.
			 By default (submode&31=0) outpul everything, otherwise
			 .1 (bit 0) write G=Hz matrix
			 .2 (bit 1) write K=Lz matrix
			 .4 (bit 2) write H=Hx matrix
			 .8 (bit 3) write  L=Lx matrix
			 .16 (bit 4) write P vector
			 In addition, mode=3.32 (just one bit set) in combination with
			  codewords file 'finC' forces matrix transformation mode
			 Use 'fout=' command line argument to generate file names
			 ${fout}H.mmx, ${fout}G.mmx, ${fout}L.mmx, ${fout}K.mmx, and ${fout}P.mmx
			 with 'fout=stdout' all output is sent to 'stdout'
			 with 'finC' set, use codewords to create G and/or K matrix
	 debug=[integer]	: bitmap for aux information to output (default: 1)
		*   0: clear the entire debug bitmap to 0.
		*   1: output misc general info (on by default)
		*   2: output matrices for verification
			 see the source code for more options
	 See program documentation for input file syntax.
	 Multiple 'debug' parameters are XOR combined except for 0.
	 Use debug=0 as the 1st argument to suppress all debug messages.
```
### Additional details

- The command-line argument `seed` is used when a positive value is
  specified.  When a negative value `-x` is specified, a combination
  of `time(NULL)`, `getpid()` and `x` is used to provide maximum
  randomness.  Namely, 
  ```C
  seed = x + time(NULL) + 1000000ul * getpid();
  ```
- The command-line argument `maxW` can be used to ensure that all
  codewords of higher weight are omitted.  This is useful with
  `mode=3.32` (matrix transformation) as the complexity grows
  exponentially with the weight.  [Currently only transformations
  corresponding to codewords of weight `1`, `2`, and `3` are
  implemented.]

## Libraries 

The program uses `m4ri` library for binary linear algebra.  To install
under Ubuntu, run
```
sudo apt-get update -y
sudo apt-get install -y libm4ri-dev
```

`Tiny Mersenne Twister` written by Mutsuo Saito and Makoto Matsumoto
is used for random number generation (header file `src/tinymt64.h` is
included with the distribution).

`uthash` by Troy D. Hanson and Arthur O'Dwyer is used for hashing
storage (header file `src/uthash.h` is included with the
distribution).

Shell scripts in the `examples/` directory assume command-line
versions of `PyMatching` and `Stim` packages compiled and located in
`../PyMatching` and `../Stim` (with respect to the location of this
file).  These excellent packages written by Oscar Higgott and Craig
Gidney, respectively, are available from `GitHub`. Please refer to the
documentation of these packages for the installation instructions.

## Future

Eventually, more sophisticated algorithms will be added to the
program.  Currently in the works are serial BP decoder and stat-mech
maximum-likelihood decoder, as well as some degeneracy-reducing matrix
transformations for `mode=3`.

